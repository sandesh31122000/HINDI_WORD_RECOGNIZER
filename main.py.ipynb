{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8631365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3b0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories={}\n",
    "categories={0: 'अ', 1: 'आ', 2: 'इ', 3: 'ई', 4: 'उ', 5: 'ऊ', 6: 'ए', 7: 'ऐ', 8: 'ओ', 9: 'औ', 10: 'अं', 11: 'अः', 12: 'क', 13: 'ख', 14: 'ग', 15: 'घ', 16: 'ङ', 17: 'च', 18: 'छ', 19: 'ज', 20: 'झ', 21: 'ञ', 22: 'ट', 23: 'ठ', 24: 'ड', 25: 'ढ', 26: 'ण', 27: 'त', 28: 'थ', 29: 'द', 30: 'ध', 31: 'न', 32: 'प', 33: 'फ', 34: 'ब', 35: 'भ', 36: 'म', 37: 'य', 38: 'र', 39: 'ल', 40: 'व', 41: 'श', 42: 'ष', 43: 'स', 44: 'ह', 45: 'क्ष', 46: 'त्र', 47: 'ज्ञ', 48: 'ा'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86d919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_detect(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray= cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    gray=cv2.medianBlur(gray,5)\n",
    "    rect,thresh=cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10\n",
    "    lines = cv2.HoughLinesP(thresh,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    if(len(lines[0][0])!=0):\n",
    "        x1,y1,x2,y2=lines[0][0]\n",
    "        return x1,y1,x2,y2\n",
    "    else:\n",
    "        return 0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf1fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust(x1,y1,x2,y2,img):\n",
    "    mid_width=img.shape[1]//2\n",
    "    mid_height=img.shape[0]//2\n",
    "    if(y1<mid_height and y2<mid_height):\n",
    "        img=img\n",
    "    elif(x1<mid_width and x2<mid_width):\n",
    "        img=cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif(x1>mid_width and x2>mid_width):\n",
    "        img=cv2.rotate(img,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "    elif(y1>mid_height and y2>mid_height):\n",
    "        img=cv2.flip(img,1)\n",
    "        img=cv2.flip(img,0)\n",
    "    return img\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7485b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(x1,y1,x2,y2,w1,z1,w2,z2,img):\n",
    "    return img[y1+3:max(z1,z2),x1:max(x2,z2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6f64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(crop):\n",
    "    height=crop.shape[0]\n",
    "    width=crop.shape[1]\n",
    "    crop1=cv2.cvtColor(crop,cv2.COLOR_RGB2GRAY)\n",
    "    rect,thresh=cv2.threshold(crop1,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    def value(item):\n",
    "        return item[0]\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    coordinate_set=[]\n",
    "    character_set=[]\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if(height-100<h<=height+20 and width//4<w<=width):\n",
    "            cv2.rectangle(thresh, (x, y), (x+w, y+h), (254, 255, 254), 8)\n",
    "            coordinate_set.append((x,x+w,y,y+h))\n",
    "    coordinate_set=sorted(coordinate_set,key=value)\n",
    "    for x in coordinate_set:\n",
    "        character_set.append(crop[x[2]:x[3],x[0]:x[1]].copy())\n",
    "    return character_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0aef29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    string=\"\"\n",
    "    original_height=100\n",
    "    original_weight=100\n",
    "    model = keras.models.load_model(\"tessaract.h5\")\n",
    "    path=str(input(\"please enter img path:\"))\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    x1,y1,x2,y2=line_detect(img)\n",
    "    adjusted_image=adjust(x1,y1,x2,y2,img)\n",
    "    crop_x1,crop_y1,crop_x2,crop_y2=line_detect(adjusted_image)\n",
    "    crop_w1,crop_z1,crop_w2,crop_z2=line_detect(cv2.flip(adjusted_image,0))\n",
    "    crop=crop_image(crop_x1,crop_y1,crop_x2,crop_y2,crop_w1,crop_z1,crop_w2,crop_z2,adjusted_image)\n",
    "    character_set=image_segmentation(crop)\n",
    "    for x in character_set:\n",
    "        x=cv2.cvtColor(x,cv2.COLOR_BGR2GRAY)\n",
    "        rect,x=cv2.threshold(x,125,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        x=cv2.resize(x,(32,32))\n",
    "        x= cv2.morphologyEx(x, cv2.MORPH_CLOSE,None,iterations=1)\n",
    "        new_img=x.reshape(-1,32,32,1)\n",
    "        new_img=new_img/255\n",
    "        value=categories[np.argmax(model.predict(new_img))]\n",
    "        string=string+str(value)\n",
    "        print(value)\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905f294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51f697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0eaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
